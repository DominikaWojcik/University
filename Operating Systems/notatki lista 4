Zad 4.
Sprzetowe mechanizmy wspierania synchronizacji:
-Wyłączanie przerwań - działa na procesorze jednordzeniowym, ale i tak mamy spadek wydajności, bo programy mogą mieć długie sekcje krytyczne, a my nie będziemy mogli ich wywłaszczyć. Nie działa całkowicie na procesorze o wielu rdzeniach z przyczyn oczywistych.
-Specjalne instrukcje maszynowe
int compare and swap ( int* word, int testval, int newval)
{
	int oldval = *word;
	if(oldval == testval) *word = newval;
	return oldval;
}

void exchange(int* register, int* memory)
{
	int tmp;
	tmp = *memory;
	*memory = *register
	*register = tmp;
}

Atomowe - albo wszystko albo nic, efekty widzimy całe albo żadne

Łatwe w użyciu, działa na wieloprocesorowych kompach, wiele sekcji krytycznych może być obsługiwane. Każda sekcja krytyczna może byc utożsamiona z jakąś zmienną.
Wady takie, że jest tutaj używany aktywne czekanie, może wystąpić głodzenie, i zakleszczenie: P1 o niskim priorytecie wchodzi do sekcji krytycznej i zostaje przerwany. P2 o wyższym priorytecie chce wejśc do sekcji, ale się to nie udaje, więc aktywnie czeka. Ponieważ priorytet P1 jest niższy, to nigdy nie wróci z powrotem do procesora.

spin_lock:
	mov eax 0 ;;wartosc do testowania
	lock cmpxchg [var] 1 ;; jesli var to 0 to var rowne 1 flaga zf na 1. Jesli var to 1, to eax = var i zf = 0
	jnz spin_lock
	ret

spin_unlock:
	mov [var] 0
	ret

Zad. 5

spinlock: mieli sie, poki wartosc dzielona nie bedzie zerem. jesli jest zerem, to wpisuje 1 w jej miejsce i przechodzi do sekcji krytycznej
po wyjsciu wpisuje 0 do zmiennej zamka.

Wada: aktywne czekanie - traci czas procesora
Zaleta: łatwe do napisania, dobre jeśli czas czekania na dostęp do sekcji krytycznej ma być bardzo krótki.

Blokowanie:
Zaleta taka, że nie traci się cykli procesora na czekanie, szczególnie jesli miałoby się czekać długo.
Wada: Zeby zatrzymać proces, należy użyć jakiegoś wywołania systemowego, co zmusza nas do zmiany trybu pracy, co jest kosztowne, jeśli dużo procesów konkuruje o dostęp do sekcji. W silnych semaforach mamy kolejkę FIFO, przez co nie ma rozróżnienia na priorytety procesów. W słabych semaforach może występować zjawisko głodzenia.

Semafory dzialaja jak system calle, czyli przechodzą do trybu jadra (??) na to wychodzi!


Futex - Fast user space mutex
Kiedy nie ma rywalizacji, unika się przechodzenia do trybu nadzorcy, wykonuje sie operacje w przestrzeni użytkownika.

Procesy mają adres współdzielonej pamięci (adresy te w procesach mogą być różne, ale w rzeczywistości wskazywać do tego samego). Futex ma licznik domyslnie ustawiony na 1. 

Futex wait zmniejsza o 1 licznik. Jesli licznik jest nieujemny, to oznacza, ze nie ma rywalizacji i można przejsc do sekcji krytycznej. Jesli jest ujemny, to oznacza, ze jest rywalizacja i za posrednictwem system calla futex() wysyla sie proces do kolejki zablokowanych.

Futex wake zwieksza o 1 licznik. Jesli licznik nie jest dodatni, to trzeba wybudzic dowolną liczbe uspionych procesów. uzywa sie do tego system calla futex(2). Jesli zwiększono licznik z 0 do 1, to oznacza, ze nie bylo rywalizacji, więc nic nie trzeba robić.

Zad. 6

4 warunki konieczne do deadlocka:
1) Wzajemna rozłączność - zasoby mogą być używane tylko przez 1 proces w danym czasie
2) Trzymanie i czekanie - Proces uzyskuje dostęp do zasobu i póki nie będzie miał wszystkich potrzebnych zasobów, czeka nie zwalniając posiadanych.
3) Brak wywłaszczania zasobów - nie można siłą zabrać procesowi zasobu
Te trzy są wg. Stallingsa konieczne, ale niewystarczalne do zaistnienia
4) Cykliczna zależność - W dwudzielnym grafie alokacji zasobów mamy cykl:
PROC  RES
O      O
O 	   O
O      O
O      O

Krawedz z procesu do zasobu oznacza żądanie uzyskania dostepu, krawedz z zasobu do procesu oznacza, ze zasób jest trzymany przez wskazany proces.

3 sposoby radzenia sobie: zapobieganie, unikanie, wykrywanie,
pierwsze polega na tym, zeby powstanie zakleszczenia bylo niemozliwe, unikanie polega na odpowiednim dokonywaniu wyborów w trakcie przydzielania zasobów, wykrywanie polega na znajdywaniu i rozwiązywaniu zakleszczeń.

Mozna zapobiegać zakleszczeniu posrednio poprzez wyeleminowanie jednego z pierwszych trzech warunków lub bezposrednio zapobiegając powstaniu czwartego.

1) nie da sie wyłączyć wzajemnej rozłączności z oczywistych powodów, wszystko sie moze posypac

2) można zablokowac proces, ktory nie ma jeszcze wszystkich zasobów i wznowić go dopiero, gdy wszystkie zasoby beda dostepne. To nie jest wydajne, bo proces może czekać bardzo długo, nawet w momentach, kiedy potrzebuje tylko części zasobów. Poza tym może się zdarzyć, że któreś z zasobów przez długi czas nie będą potrzebne, a mogłyby zostac uzyte w tym samym czasie przez jakis inny proces. Nawet nie wspominając o tym, że nie wiadomo, czy proces będzie wiedział zawczasu czego potrzebuje.

3) Można wyeliminować brak wywłaszczania zasobów tak, że kiedy proces żąda dostępu do zajętego zasobu, musi zwolnić wszystkie dotychczasowo zajęte zasoby i potem ewentualnie jeszcze raz ich zażądać. 
Ewentualnie, jeśli proces żąda zasobu posiadanego przez inny proces, to system może wywłaszczyć drugi proces z tego zasobu. To by zapobiegało deadlockom gdyby każdy proces miał inny priorytet. Działałoby tylko dla zasobów, których stan można łatwo zapisać i odtwarzać później tak jak to jest z procesorem.

4) Można wprowadzić porządek liniowy na zasobach. Jeśli proces uzyska zasób R_i, to może potem żądać zasobów dla j > i. Teraz nie może dojść do zakleszczenia, bo Jeśli jeden proces miałby R_i, a drugi R_j, (i < j), to jest to niemożliwe, bo drugi proces musiałby najpierw dostać R_i. 
Tutaj mamy taki sam argument jak w przypadku czekania. rezerwujemy zasoby, ktorych moze jeszcze nie potrzebujemy.

Zjawisko odwrócenia priorytetów: Dwa procesy o róznych priorytetach wymagają tego samego zasobu. Proces o niższym priorytecie zajął zasób i w ten sposób proces o wyższym priorytecie musi czekać, aż procesy o niższym priorytecie wykonają swoje zadania.

W 1997 wysłano łazik na marsa Mars Pathfinder, który wysyłał dane na Ziemię. Ale po paru dniach okazało się, że system łazika się często resetuje, co powodowało utratę danych.

Mial 3 zadania o priorytetach od najwiekszego do najmniejszego:
T1 - Co jakiś czas sprawdzaj, czy system jakoś się trzyma - ustawia timer, ktory musi resetować, jeśli timer sie odpali, to resetowany jest cały system, co trwa 1 dzień.
T2 - przetwarzanie obrazów
T3 - Sprawdzanie jakiejs częsci wyposażenia.

T1 i T3 współdzieliły ten sam zasób (pewną część wyposażenia) na ktory miały semafor s.

Nastepujace zdarzenia powodowały odwrócenie priorytetów:
1) T3 zaczyna sie wykonywac
2) T3 zajmuje zasób i wchodzi do sekcji krytycznej
3) T1 ma wyzszy priorytet, wywlaszcza T3 i uruchamia sie
4) T1 probuje zając zasób, ale jest on zajety przez T3, T1 sie blokuje, T3 wznawia prace w sekcji krytycznej.
5) T2 ma wyzszy priorytet, wiec wywłaszcza T3 i mieli się przez jakiś czas
6) Potem T2 z jakiegoś powodu się zawiesza i T3 zostaje wznowiony
7) T3 konczy sekcję krytyczną, T1 zostaje wyciągnięte z kolejki zablokowanych, wywłaszcza T3 i wchodzi do sekcji krytycznej.

Dwa rozwiazania:
1) Dziedziczenie priorytetu: Procesy o niższym priorytecie, które zajęły potrzebny przez ważniejszy proces zasób, dostają priorytet ważniejszego procesu dopóki nie zwolnią zasobu. Dziedziczenie odbywa sie od razu, gdy proces ważniejszy zostaje zablokowany. - Tak zrobiono z łazikiem.

2) priority ceiling - ograniczenie z góry / sufitowanie (??)
Ustawiano zasobom priorytet o 1 większy od najważniejszego z jego użytkowników. Planista w trakcie działania wyznacza priorytet zadaniom, które uzywają zasobu. Po zakonczeniu operacji na zasobie, priorytet zadania wraca do normy.

W windowsie jest takie cos jak Autoboost, co sprawdza zależności między procesami i wątkami i boostuje priorytet watków o niskim priorytecie, które przetrzymują zasoby potrzebne przez wątki o wyższym priorytecie.

Zad. 7

Condition variable to po prostu kolejka zablokowanych procesów.

Condition variable udostępnia 3 funkcje:

cwait(cond x, mutex m):
1. Atomowo:
-zwalnia blokadę m, 
-wkłada do kolejki uspionych wątek,
-usypia wątek.g
Musi być atomowo, by nie było missed wake-up'u
2 .Kiedy wątek zostanie wybudzony, musi od razu zablokować swoją blokadę.

csignal/notify(cond x):
Wskazuje, że warunek zmiennej staje się prawdą, wybudza jeden lub więcej procesów i przenosi je do kolejki gotowych/ albo jakiejs innej.
Zależnie od implementacji proces sygnalizujący może albo się przerwać i wznowić uśpiony proces, albo wykonać się do końca. Zależy od monitorów - Hoare(Natychmiast wznowić wzbudzoną), Mesa(Pozwolić wykonać się do końca).

W mesa cnotify mamy watchdog timer: proces, który przeczekał maksymalny timeout zostanie wybudzony nieważne, czy warunek jest już spełniony. To chroni przed wiecznym zablokowaniem.

broadcast/notifyAll(cond x) - monitory Mesa
Wybudza wszytkie procesy z kolejki uśpionych.
Możemy nie wiedzieć, ile procesów mamy wybudzić, np. w problemie konsumenta i producenta, producent moze tworzyc bloki danych a konsument zjadać blok. Jesli mamy kilku konsumentów, którzy mogą zjadać rozne bloki, to lepiej wybudzić wszystkich.

Monitory: konstrukt języków programowania - Zapewniają wzajemną rozłączność, programista musi zadbać o synchronizacje, ma do tego zmienne warunkowe.

Monitor to struktura danych posiadająca swoje lokalne dane, kod inicjalizacyjny, procedury oraz zmienne warunkowe.

Dostęp do tych danych może odbyć się wyłącznie ze środka monitora, zadna zewnętrzna funkcja nie ma do nich dostępu.
Tylko procedury monitora mogą korzystać z danych monitora.
Tylko jeden proces może się na raz wykonywać w monitorze.

Wątki chcące dostać się do monitora czekają w kolejce na wejście.
Wewnątrz uruchamiają procedurę monitora i mogą zablokować się na jakiejś zmiennej warunkowej. Trafiają wtedy do kolejki uśpionych i kolejny wątek wchodzi do monitora. Kiedy wątek sygnalizuje signal mogą wydarzyć się dwa scenariusze, zależnie od założen monitora.

Monitor Hoare'a:
Signal powoduje przerwanie procesu sygnalizującego i natychmiastowe wznowienie uspionego na zmiennej warunkowej procesu. Uspiony trafa do tak zwanej urgent queue, którą w przyszłości priorytetyzuje się nad kolejką do wejscia do monitora.
Mamy 2 problemy: 
1) marnujemy 2 zmiany kontekstu: jedna na zablokowanie sygnalizującego procesu, druga na zmianę z powrotem na dokończenie go.
2) Planista musi być perfekcyjny: nie może pozwolić, by zaden inny proces nie wszedł przypadkiem do monitora przed uwolnionym procesem, bo to może zmienic warunek. W dodatku co jeśli proces sygnalizujący się wyłoży? Wtedy proces mógłby być zablokowany wiecznie.

Monitor Mesa:
Skoro proces wykonał juz signal, to pewnie skończył większość roboty - można pozwolić mu się wykonać do końca. Wybudzone procesy mogą sobie poczekać w entry queue. Daje to problem: warunki potrzebne wybudzonym procesom mogły sie w międzyczasie zmienić.
Dlatego zamiast if(!warunek)cwait(), dajemy while(!warunek)cwait(), co ewidentnie działa.

w linuxie jest conditional var mesa

Przykład: proces konsumenta i producenta //Stallings.

Zad. 8

Send(destination, message)
Receive(source, message)

Teraz send i receive mogą się blokować albo nie blokować
1) Blocking send i blocking recive: dobre do ścisłej synchronizacji. sender i receiver spotykają się w jednym punkcie czasu - rendezvous - punkt schadzki. 
2) Non-blocking send i blocking receive - np. serwer oczekuje na żądania i bez nich nie ma nic do roboty.
3) non blocking i non blocking - żadna ze stron nie musi czekać
czwarta opcja nie ma sensu.

nonblocking send moze powodowac problem generowania zbyt wielkiej ilości wiadomości marnując pamięć. nonblocking send nie mówi o sukcesie dostarczenia wiadomosci, programista musi zaprojektować protokuł komunikacji z odpowiedziami.

blocking receive moze sie blokować w nieskonczonosc, jesli komunikat zostanie zgubiony. Jesli sie da nonblocking receive, to można za szybko odebrac wiadomosc i przegapic ją. Można testować, czy wiadomość przyszła przed wykonaniem receive.

Adresowanie bezpośrednie: podajemy identyfikator procesu, musimy wiedzeć wcześniej, z czym będziemy sie komunikować, albo możemy robić domniemane receive() w parametrze source zapisze nam adres nadawcy.

Adresowanie pośrednie: ustawaiamy skrzynkę pocztową i wysyłamy do niej wiadomości / odbieramy z niej wiadomości
Często skrzynka pocztowa to tak jakby port. Porty są statycznie przypisywane konkretnym procesom (tworzony i na stałe przypisywany)

Jak jest dużo wysylajacych, to dobór skrzynki może być ustalony dynamicznie, do tego sie uzywa connecta i disconnecta



Możliwości mailboxów:
1) one-to-one prywatna komunikacja
2) many-to-one wiele klientów do serwera
3) one-to-many nadajemy komunikat do dużej liczby procesów (zamykanie systemu)
4) many-to-many wiele klientów do wielu serwerów

Wiadomości mogą być krótkie o stałym rozmiarze - mało zużywamy na przechowywanie i wysyłanie.

Długie zapisywane w plikach i wysyłane wskaźniki do plików.

Zmiennej długości : nagłówek i ciało komunikatu
Nagłówek: typ komunikatu, id celu, id źródła, długość, informacje kontrolne (pointery, zeby zrobić linked liste komunikatów; numer w ciągu wiadomości, by wiedzieć, która ma być która w kolejności; priorytet wiadomości)
